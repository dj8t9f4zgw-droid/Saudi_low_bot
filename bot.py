import logging
import requests
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

TELEGRAM_TOKEN = "8048665417:AAEUWd5RCFZ3hEgOcHjnr4MRyKyvANf4-qs"
GEMINI_API_KEY = "AIzaSyA7hRs1veViDmfDqEkMZLkODp774jD6ZUE"
GEMINI_URL = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key={GEMINI_API_KEY}"

logging.basicConfig(level=logging.INFO)

def ask_gemini(question):
    prompt = f"""Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©. Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø°ÙƒØ±:
1. Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© ÙˆØ§Ø³Ù… Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ±Ù‚Ù… Ø§Ù„Ù…Ø§Ø¯Ø©
2. Ø§Ù„Ù†Øµ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ
3. Ø§Ù„Ø¬Ù‡Ø© Ø§Ù„Ù…Ø®ØªØµØ©
4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ¶Ø¹
5. Ø§Ù„ØªÙˆØµÙŠØ©

Ø§Ù„Ø³Ø¤Ø§Ù„: {question}"""
    
    payload = {"contents": [{"parts": [{"text": prompt}]}], "generationConfig": {"temperature": 0.3, "maxOutputTokens": 2048}}
    try:
        r = requests.post(GEMINI_URL, json=payload, timeout=30)
        return r.json()["candidates"][0]["content"]["parts"][0]["text"]
    except:
        return "Ø­Ø¯Ø« Ø®Ø·Ø£ØŒ Ø­Ø§ÙˆÙ„ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰."

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ğŸ›ï¸ Ù…Ø±Ø­Ø¨Ø§Ù‹! Ø£Ù†Ø§ Ø¨ÙˆØª Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©.\n\nØ§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ ÙˆØ¶Ø¹Ùƒ ÙˆØ³Ø£Ø¨Ø­Ø« Ù„Ùƒ ÙÙŠ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ©!")

async def handle(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = await update.message.reply_text("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø³â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹
